{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #DataFrame, Series\n",
    "from dateutil import parser, rrule\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "933409\n"
    }
   ],
   "source": [
    "# import trip data \n",
    "trips = pd.read_csv('Bixi_data/OD_2019-06.csv')\n",
    "\n",
    "#get size of df\n",
    "num_trips = trips.shape[0]\n",
    "print(num_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract month, day, hour to trips\n",
    "#convert string to timestamp and imputate seconds\n",
    "trips.start_date = pd.to_datetime(trips.start_date) - pd.to_timedelta(pd.to_datetime(trips.start_date).dt.second, unit='s')\n",
    "trips.end_date = pd.to_datetime(trips.end_date) - pd.to_timedelta(pd.to_datetime(trips.end_date).dt.second, unit='s')\n",
    "#extract month from timestamp\n",
    "trips['month'] = trips.start_date.dt.month\n",
    "#extract weekday from timestamp\n",
    "trips['weekday'] = trips.start_date.dt.weekday\n",
    "#extract hour from timestamp\n",
    "trips['hour'] = trips.start_date.dt.hour\n",
    "trips['round_to_hour'] = trips.start_date.dt.round(\"H\")\n",
    "#extract date from timestamp\n",
    "trips['date'] = trips.start_date.dt.date\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import temp data\n",
    "temp = pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_06-2019_P1H.csv')\n",
    "# Commented out since it takes way too long to compute all the data\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_05-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_06-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_07-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_08-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_09-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_10-2019_P1H.csv'))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of temperature data\n",
    "# concatinate date and time with temperature\n",
    "temp_df = pd.concat([temp['Date/Time'], temp['Temp (Â°C)']], axis=1)\n",
    "temp_df['Date/Time'] = pd.to_datetime(temp_df['Date/Time'])\n",
    "temp_df = temp_df.set_index('Date/Time').T\n",
    "# convert df to dictionary\n",
    "temp_dict = temp_df.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import precipitation data\n",
    "precip = pd.read_csv('Weather_data/Daily/en_climate_daily_QC_702S006_2019_P1D.csv')\n",
    "# dictionary of rain data\n",
    "rain_df = pd.concat([precip['Date/Time'], precip['Total Precip (mm)']], axis=1)\n",
    "rain_df['Date/Time'] = pd.to_datetime(rain_df['Date/Time'])\n",
    "rain_df['Date/Time'] = rain_df['Date/Time'].dt.date\n",
    "# fill na with 0\n",
    "rain_df = rain_df.fillna(0)\n",
    "# get the transpose of the df to generate dictionary of date and rain\n",
    "rain_df = rain_df.set_index('Date/Time').T\n",
    "rain_dict = rain_df.to_dict('list')\n",
    "# dictionary of snow data\n",
    "snow_df = pd.concat([precip['Date/Time'], precip['Total Snow (cm)']], axis=1)\n",
    "snow_df['Date/Time'] = pd.to_datetime(snow_df['Date/Time'])\n",
    "snow_df['Date/Time'] = snow_df['Date/Time'].dt.date\n",
    "snow_df = snow_df.fillna(0)\n",
    "# transpose the df to get dictionary\n",
    "snow_df = snow_df.set_index('Date/Time').T\n",
    "snow_dict = snow_df.to_dict('list')\n",
    "#map weather to trips\n",
    "trips['Temp'] = trips.round_to_hour.map(temp_dict)\n",
    "trips['Rain'] = trips.date.map(rain_dict)\n",
    "trips['Snow'] = trips.date.map(snow_dict)\n",
    "\n",
    "# change Temp column from object to int and fill NaN values\n",
    "trips['Temp'] = (trips.Temp.str[0])\n",
    "trips['Temp'] = pd.to_numeric(trips.Temp , errors='ignore')\n",
    "trips['Temp'] = trips.Temp.fillna(0)\n",
    "trips['Temp'] = trips.Temp.astype(int)\n",
    "\n",
    "# # change Rain column from object to int and fill NaN values\n",
    "trips['Rain'] = (trips.Rain.str[0])\n",
    "trips['Rain'] = pd.to_numeric(trips.Rain, errors='ignore')\n",
    "trips['Rain'] = trips.Rain.fillna(0)\n",
    "trips['Rain'] = trips.Rain.astype(int)\n",
    "\n",
    "# change Snow column from object to int and fill NaN values\n",
    "trips['Snow'] = (trips.Snow.str[0])\n",
    "trips['Snow'] = pd.to_numeric(trips.Snow, errors='ignore')\n",
    "trips['Snow'] = trips.Snow.fillna(0)\n",
    "trips['Snow'] = trips.Snow.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute trip volumes \n",
    "# compute number of bikes checked out\n",
    "first = min(trips.start_date)\n",
    "last = max(trips.end_date)\n",
    "# creates list which has the date for every minute\n",
    "vol_time = list(rrule.rrule(freq=rrule.MINUTELY, dtstart=first, until=last))\n",
    "# empty list \n",
    "vol_val = np.zeros(len(vol_time))\n",
    "# creates dictionary for the time and the value\n",
    "vol_dict = dict(zip(vol_time, vol_val))\n",
    "# fill volume dictionary\n",
    "for i in np.arange(num_trips):\n",
    "    start = trips.start_date.iloc[i]\n",
    "    end = trips.end_date.iloc[i]\n",
    "    # check every trips, if a minute belongs to it then increment the occurrance of that minute\n",
    "    for j in list(rrule.rrule(freq=rrule.MINUTELY, dtstart=start, until=end)):\n",
    "        vol_dict[j] += 1\n",
    "trips['volume'] = trips.start_date.map(vol_dict)\n",
    "volume = trips.volume.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Data\n",
    "nat_df = pd.concat([trips['Temp'], trips['Rain'], trips['Snow'], \n",
    "                   trips['hour'], trips['weekday'], trips['month'],\n",
    "                     trips['volume']], axis=1)\n",
    "x_df_nat = nat_df.drop(['volume'], axis=1)\n",
    "x_matrix_nat = x_df_nat.astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineered data\n",
    "eng_df = nat_df\n",
    "# weekday processing \n",
    "eng_df.weekday = eng_df.weekday.replace(np.arange(5), 1)\n",
    "# set weekends to 0\n",
    "eng_df.weekday = eng_df.weekday.replace(5, 0)\n",
    "eng_df.weekday = eng_df.weekday.replace(6, 0)\n",
    "# rain processing\n",
    "# set to 1 if more than 0 (binary data encoding)\n",
    "eng_df.loc[eng_df.Rain > 0] = 1\n",
    "\n",
    "# snow processing\n",
    "# set to 1 if more than 0 (binary data encoding)\n",
    "eng_df.loc[eng_df.Snow > 0] = 1\n",
    "#eng['Snow'][eng['Snow'] > 0] = 1\n",
    "\n",
    "# season processing\n",
    "# set warm months to 1\n",
    "eng_df.month = eng_df.month.replace(np.arange(5,10), 1)\n",
    "# non warm months to 0\n",
    "eng_df.month = eng_df.month.replace(4, 0)\n",
    "eng_df.month = eng_df.month.replace(np.arange(10,13), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_eng = eng_df.drop(['volume'], axis=1)\n",
    "x_matrix_eng = x_df_eng.astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "# use 70% of dataset for training, rest for testing\n",
    "nat_train = int(num_trips*0.70)\n",
    "# create array size of n_train and get random values from n_trips to fill it\n",
    "train_id = np.random.choice(num_trips, nat_train, replace=False)\n",
    "# create test set\n",
    "test_id = np.array(list(set(range(num_trips))-set(train_id)))\n",
    "num_test = num_trips - nat_train\n",
    "# training datasets\n",
    "x_train_nat = x_matrix_nat[train_id,:]\n",
    "x_train_eng = x_matrix_eng[train_id,:]\n",
    "y_train = volume[train_id]\n",
    "# testing dataset\n",
    "x_test_nat = x_matrix_nat[test_id,:]\n",
    "x_test_eng = x_matrix_eng[test_id,:]\n",
    "y_test = volume[test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Functions\n",
    "def rmse(predict, test):\n",
    "    num_test = len(predict)\n",
    "    error = 1/num_test * np.sqrt(sum((predict - test)**2))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty arrays\n",
    "rmse_vec_nat = np.zeros(10)\n",
    "percent_vec_nat = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a regression for natural data\n",
    "#trains the dataset\n",
    "for i in [10,20,30,40,50,60,70,80,90,100]:\n",
    "    rf = RandomForestRegressor(min_samples_leaf = 10, n_estimators = i)\n",
    "    rf.fit(x_train_nat, y_train)\n",
    "    rf_predict = rf.predict(x_test_nat)\n",
    "    rmse_vec_nat[int(i/10)-1] = rmse(rf_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty arrays\n",
    "rmse_vec_eng = np.zeros(10)\n",
    "percent_vec_eng = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"numpy.float64\") to str",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-523cc4cf0e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrf_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_eng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrmse_vec_eng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE for \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\" estimators \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrmse_vec_eng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"numpy.float64\") to str"
     ]
    }
   ],
   "source": [
    "#random forest for engineering data\n",
    "for i in [10,20,30,40,50,60,70,80,90,100]:\n",
    "    rf = RandomForestRegressor(min_samples_leaf = 10, n_estimators = i)\n",
    "    rf.fit(x_train_eng, y_train)\n",
    "    rf_predict = rf.predict(x_test_eng)\n",
    "    rmse_vec_eng[int(i/10)-1] = rmse(rf_predict, y_test)\n",
    "    print(\"RMSE for \", i ,\" estimators \" + str(rmse_vec_eng[int(i/10)-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}