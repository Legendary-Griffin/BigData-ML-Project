{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser, rrule\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd #DataFrame, Series\n",
    "import time\n",
    "import graphviz\n",
    "import pydotplus\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "933409\n"
    }
   ],
   "source": [
    "# import trip data \n",
    "trips = pd.read_csv('Bixi_data/OD_2019-06.csv')\n",
    "\n",
    "#get size of df\n",
    "num_trips = trips.shape[0]\n",
    "print(num_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "start_date  start_station_code            end_date  \\\n0      2019-06-01 00:00:00                6026 2019-06-01 00:03:00   \n1      2019-06-01 00:00:00                6197 2019-06-01 00:24:00   \n2      2019-06-01 00:00:00                6435 2019-06-01 00:11:00   \n3      2019-06-01 00:00:00                7036 2019-06-01 00:21:00   \n4      2019-06-01 00:00:00                7003 2019-06-01 00:12:00   \n...                    ...                 ...                 ...   \n933404 2019-06-30 23:59:00                6015 2019-07-01 00:10:00   \n933405 2019-06-30 23:59:00                6012 2019-07-01 00:30:00   \n933406 2019-06-30 23:59:00                6119 2019-07-01 00:35:00   \n933407 2019-06-30 23:59:00                5007 2019-07-01 00:35:00   \n933408 2019-06-30 23:59:00                6408 2019-07-01 00:03:00   \n\n        end_station_code  duration_sec  is_member  month  weekday  hour  \\\n0                   6036           197          0      6        5     0   \n1                   6006          1436          1      6        5     0   \n2                   7082           702          1      6        5     0   \n3                   6213          1289          0      6        5     0   \n4                   6019           721          1      6        5     0   \n...                  ...           ...        ...    ...      ...   ...   \n933404              6248           683          0      6        6    23   \n933405              6313          1893          1      6        6    23   \n933406              6026          2151          1      6        6    23   \n933407              5005          2138          1      6        6    23   \n933408              6401           220          1      6        6    23   \n\n       round_to_hour        date  \n0         2019-06-01  2019-06-01  \n1         2019-06-01  2019-06-01  \n2         2019-06-01  2019-06-01  \n3         2019-06-01  2019-06-01  \n4         2019-06-01  2019-06-01  \n...              ...         ...  \n933404    2019-07-01  2019-06-30  \n933405    2019-07-01  2019-06-30  \n933406    2019-07-01  2019-06-30  \n933407    2019-07-01  2019-06-30  \n933408    2019-07-01  2019-06-30  \n\n[933409 rows x 11 columns]\n"
    }
   ],
   "source": [
    "# extract month, day, hour to trips\n",
    "#convert string to timestamp and imputate seconds\n",
    "trips.start_date = pd.to_datetime(trips.start_date) - pd.to_timedelta(pd.to_datetime(trips.start_date).dt.second, unit='s')\n",
    "trips.end_date = pd.to_datetime(trips.end_date) - pd.to_timedelta(pd.to_datetime(trips.end_date).dt.second, unit='s')\n",
    "#extract month from timestamp\n",
    "trips['month'] = trips.start_date.dt.month\n",
    "#extract weekday from timestamp\n",
    "trips['weekday'] = trips.start_date.dt.weekday\n",
    "#extract hour from timestamp\n",
    "trips['hour'] = trips.start_date.dt.hour\n",
    "trips['round_to_hour'] = trips.start_date.dt.round(\"H\")\n",
    "#extract date from timestamp\n",
    "trips['date'] = trips.start_date.dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import temp data\n",
    "temp = pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_06-2019_P1H.csv')\n",
    "# Commented out since it takes way too long to compute all the data\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_05-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_06-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_07-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_08-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_09-2019_P1H.csv'))\n",
    "# temp = temp.append(pd.read_csv('Weather_data/Hourly/en_climate_hourly_QC_702S006_10-2019_P1H.csv'))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# dictionary of temperature data\n",
    "# concatinate date and time with temperature\n",
    "temp_df = pd.concat([temp['Date/Time'], temp['Temp (Â°C)']], axis=1)\n",
    "temp_df['Date/Time'] = pd.to_datetime(temp_df['Date/Time'])\n",
    "temp_df = temp_df.set_index('Date/Time').T\n",
    "# convert df to dictionary\n",
    "temp_dict = temp_df.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import precipitation data\n",
    "precip = pd.read_csv('Weather_data/Daily/en_climate_daily_QC_702S006_2019_P1D.csv')\n",
    "# dictionary of rain data\n",
    "rain_df = pd.concat([precip['Date/Time'], precip['Total Precip (mm)']], axis=1)\n",
    "rain_df['Date/Time'] = pd.to_datetime(rain_df['Date/Time'])\n",
    "rain_df['Date/Time'] = rain_df['Date/Time'].dt.date\n",
    "# fill na with 0\n",
    "rain_df = rain_df.fillna(0)\n",
    "# get the transpose of the df to generate dictionary of date and rain\n",
    "rain_df = rain_df.set_index('Date/Time').T\n",
    "rain_dict = rain_df.to_dict('list')\n",
    "# dictionary of snow data\n",
    "snow_df = pd.concat([precip['Date/Time'], precip['Total Snow (cm)']], axis=1)\n",
    "snow_df['Date/Time'] = pd.to_datetime(snow_df['Date/Time'])\n",
    "snow_df['Date/Time'] = snow_df['Date/Time'].dt.date\n",
    "snow_df = snow_df.fillna(0)\n",
    "# transpose the df to get dictionary\n",
    "snow_df = snow_df.set_index('Date/Time').T\n",
    "snow_dict = snow_df.to_dict('list')\n",
    "#map weather to trips\n",
    "trips['Temp'] = trips.round_to_hour.map(temp_dict)\n",
    "trips['Rain'] = trips.date.map(rain_dict)\n",
    "trips['Snow'] = trips.date.map(snow_dict)\n",
    "\n",
    "# change Temp column from object to int and fill NaN values\n",
    "trips['Temp'] = (trips.Temp.str[0])\n",
    "trips['Temp'] = pd.to_numeric(trips.Temp , errors='ignore')\n",
    "trips['Temp'] = trips.Temp.fillna(0)\n",
    "trips['Temp'] = trips.Temp.astype(int)\n",
    "\n",
    "# # change Rain column from object to int and fill NaN values\n",
    "trips['Rain'] = (trips.Rain.str[0])\n",
    "trips['Rain'] = pd.to_numeric(trips.Rain, errors='ignore')\n",
    "trips['Rain'] = trips.Rain.fillna(0)\n",
    "trips['Rain'] = trips.Rain.astype(int)\n",
    "\n",
    "# change Snow column from object to int and fill NaN values\n",
    "trips['Snow'] = (trips.Snow.str[0])\n",
    "trips['Snow'] = pd.to_numeric(trips.Snow, errors='ignore')\n",
    "trips['Snow'] = trips.Snow.fillna(0)\n",
    "trips['Snow'] = trips.Snow.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute trip volumes \n",
    "# compute number of bikes checked out\n",
    "first = min(trips.start_date)\n",
    "last = max(trips.end_date)\n",
    "# creates list which has the date for every minute\n",
    "vol_time = list(rrule.rrule(freq=rrule.MINUTELY, dtstart=first, until=last))\n",
    "# empty list \n",
    "vol_val = np.zeros(len(vol_time))\n",
    "# creates dictionary for the time and the value\n",
    "vol_dict = dict(zip(vol_time, vol_val))\n",
    "# fill volume dictionary\n",
    "for i in np.arange(num_trips):\n",
    "    start = trips.start_date.iloc[i]\n",
    "    end = trips.end_date.iloc[i]\n",
    "    # check every trips, if a minute belongs to it then increment the occurrance of that minute\n",
    "    for j in list(rrule.rrule(freq=rrule.MINUTELY, dtstart=start, until=end)):\n",
    "        vol_dict[j] += 1\n",
    "trips['volume'] = trips.start_date.map(vol_dict)\n",
    "volume = trips.volume.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Data\n",
    "nat_df = pd.concat([trips['Temp'], trips['Rain'], trips['Snow'], \n",
    "                   trips['hour'], trips['weekday'], trips['month'],\n",
    "                     trips['volume']], axis=1)\n",
    "x_df_nat = nat_df.drop(['volume'], axis=1)\n",
    "x_matrix_nat = x_df_nat.astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineered data\n",
    "eng_df = nat_df\n",
    "# weekday processing \n",
    "eng_df.weekday = eng_df.weekday.replace(np.arange(5), 1)\n",
    "# set weekends to 0\n",
    "eng_df.weekday = eng_df.weekday.replace(5, 0)\n",
    "eng_df.weekday = eng_df.weekday.replace(6, 0)\n",
    "# rain processing\n",
    "# set to 1 if more than 0 (binary data encoding)\n",
    "eng_df.loc[eng.Rain > 0] = 1\n",
    "\n",
    "# snow processing\n",
    "# set to 1 if more than 0 (binary data encoding)\n",
    "eng_df.loc[eng.Snow > 0] = 1\n",
    "#eng['Snow'][eng['Snow'] > 0] = 1\n",
    "\n",
    "# season processing\n",
    "# set warm months to 1\n",
    "eng_df.month = eng_df.month.replace(np.arange(5,10), 1)\n",
    "# non warm months to 0\n",
    "eng_df.month = eng_df.month.replace(4, 0)\n",
    "eng_df.month = eng_df.month.replace(np.arange(10,13), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_df_eng = eng_df.drop(['volume'], axis=1)\n",
    "x_matrix_eng = x_df_eng.astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "# use 70% of dataset for training, rest for testing\n",
    "nat_train = int(num_trips*0.70)\n",
    "# create array size of n_train and get random values from n_trips to fill it\n",
    "train_id = np.random.choice(num_trips, nat_train, replace=False)\n",
    "# create test set\n",
    "test_id = np.array(list(set(range(num_trips))-set(train_id)))\n",
    "num_test = num_trips - nat_train\n",
    "# training datasets\n",
    "x_train_nat = x_matrix_nat[train_id,:]\n",
    "x_train_eng = x_matrix_eng[train_id,:]\n",
    "y_train = volume[train_id]\n",
    "# testing dataset\n",
    "x_test_nat = x_matrix_nat[test_id,:]\n",
    "x_test_eng = x_matrix_eng[test_id,:]\n",
    "y_test = volume[test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Functions\n",
    "def rmse(predict, test):\n",
    "    num_test = len(predict)\n",
    "    error = 1/num_test * np.sqrt(sum((predict - test)**2))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_error(predict, test):\n",
    "    error = np.mean(np.divide(np.abs(test-predict),predict))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treePlot(fit):\n",
    "    labels = ['Temperature (C)', 'Total Rain (mm)', 'Total Snow (cm)',\n",
    "         'Hour', 'Weekday', 'Month']\n",
    "    dot_data = tree.export_graphviz(fit, out_file=None, \n",
    "                                    max_depth=3, filled=True, \n",
    "                                    rounded=True,special_characters=True\n",
    "                                , feature_names = labels, impurity=False)\n",
    "\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "    colors = ('lightskyblue','mediumpurple1')\n",
    "    edges = collections.defaultdict(list)\n",
    "\n",
    "    for edge in graph.get_edge_list():\n",
    "        edges[edge.get_source()].append(int(edge.get_destination()))\n",
    "\n",
    "    for edge in edges:\n",
    "        edges[edge].sort()    \n",
    "        for i in range(2):\n",
    "            dest = graph.get_node(str(edges[edge][i]))[0]\n",
    "            dest.set_fillcolor(colors[i])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time Elapsed to fit Decision Tree Natural Data :  33.936360104000414  seconds\nBest min_samples_leaf Parameter:  {'min_samples_leaf': 10}\nNatural Data RMSE:  0.10561179860289971\nNatural Data Mean Absolute Percent Error:  0.07930057286123038\n"
    }
   ],
   "source": [
    "# parameter tests\n",
    "parameters = {'min_samples_leaf': [10,50,100,250,500,750,1000,\n",
    "                                   1250,1500,1750,2000]}\n",
    "# natural data training fit\n",
    "start_training = time.perf_counter()\n",
    "dec_tree_nat = DecisionTreeRegressor()\n",
    "fit_nat = GridSearchCV(dec_tree_nat, parameters, cv=5, refit = True)\n",
    "fit_nat.fit(x_train_nat, y_train)\n",
    "tree_predict_nat = fit_nat.predict(x_test_nat)\n",
    "\n",
    "# Best min_samples_leaf Parameter\n",
    "opt_nat = fit_nat.best_params_\n",
    "\n",
    "# Test Set fit\n",
    "tree_nat = DecisionTreeRegressor(min_samples_leaf = 10)\n",
    "tree_nat.fit(x_train_nat, y_train)\n",
    "tree_predict_nat = tree_nat.predict(x_test_nat)\n",
    "end_training = time.perf_counter()\n",
    "\n",
    "# Plot Tree\n",
    "graph = treePlot(tree_nat)\n",
    "graph.write_png('tree_natural.png')\n",
    "\n",
    "print('Computing time to fit Decision Tree using Natural Data : ', end_training - start_training,' seconds')\n",
    "print('Best min_samples_leaf Parameter: ', opt_nat)\n",
    "print('Natural Data RMSE: ', rmse(tree_predict_nat, y_test))\n",
    "print('Natural Data Mean Absolute Percent Error: ', \n",
    "      percent_error(tree_predict_nat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time Elapsed to fit Decision Tree :  23.00414419400022  seconds\nBest min_samples_leaf Parameter:  {'min_samples_leaf': 10}\nEngineered Data RMSE:  0.2891866545576817\nEngineered Data Mean Absolute Percent Error:  0.2069902620594885\n"
    }
   ],
   "source": [
    "# Engineered data training fit\n",
    "start_training = time.perf_counter()\n",
    "dec_tree_eng = DecisionTreeRegressor()\n",
    "fit_eng = GridSearchCV(dec_tree_eng, parameters, cv=5, refit = True)\n",
    "fit_eng.fit(x_train_eng, y_train)\n",
    "tree_predict_eng = fit_eng.predict(x_test_eng)\n",
    "\n",
    "# Best min_samples_leaf Parameter\n",
    "opt_eng = fit_eng.best_params_\n",
    "\n",
    "# Test Set fit\n",
    "tree_eng = DecisionTreeRegressor(min_samples_leaf = 10)\n",
    "tree_eng.fit(x_train_eng, y_train)\n",
    "tree_predict_eng = tree_eng.predict(x_test_eng)\n",
    "end_training = time.perf_counter()\n",
    "\n",
    "# Plot Tree\n",
    "graph = treePlot(tree_eng)\n",
    "graph.write_png('tree_engineered.png')\n",
    "\n",
    "print('Computing time to fit Decision Tree using Engineered Data : ', end_training - start_training,' seconds')\n",
    "print('Best min_samples_leaf Parameter: ', opt_eng)\n",
    "print('Engineered Data RMSE: ', rmse(tree_predict_eng, y_test))\n",
    "print('Engineered Data Mean Absolute Percent Error: ', \n",
    "      percent_error(tree_predict_eng, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}